1.  概述

Java REST Client 有两种风格：

Java Low Level REST Client 		  用于Elasticsearch的官方低级客户端。它允许通过http与Elasticsearch集群通信。将请求编排和响应反编排留给用户自己处理。它兼容所有的Elasticsearch版本。（PS：学过WebService的话，对编排与反编排这个概念应该不陌生。可以理解为对请求参数的封装，以及对响应结果的解析）
低级别的REST客户端，通过http与集群交互，用户需自己编组请求JSON串，及解析响应JSON串。兼容所有ES版本。

Java High Level REST Client 用于Elasticsearch的官方高级客户端。它是基于低级客户端的，它提供很多API，并负责请求的编排与响应的反编排。（PS：就好比是，一个是传自己拼接好的字符串，并且自己解析返回的结果；而另一个是传对象，返回的结果也已经封装好了，直接是对象，更加规范了参数的名称以及格式，更加面对对象一点）
（PS：所谓低级与高级，我觉得一个很形象的比喻是，面向过程编程与面向对象编程）
高级别的REST客户端，基于低级别的REST客户端，增加了编组请求JSON串、解析响应JSON串等相关api。使用的版本需要保持和ES服务端的版本一致，否则会有版本问题。

在 Elasticsearch 7.0 中不建议使用TransportClient，并且在8.0中会完全删除TransportClient。因此，官方更建议我们用Java High Level REST Client，它执行HTTP请求，而不是序列号的Java请求。既然如此，这里就直接用高级了。

高级客户端内部会创建低级客户端用于基于提供的builder执行请求。低级客户端维护一个连接池，并启动一些线程，因此当你用完以后应该关闭高级客户端，并且在内部它将会关闭低级客户端，以释放这些资源。关闭客户端可以使用close()方法


elasticsearch6.x以后一个index只能存在一个type

docker pull docker.elastic.co/elasticsearch/elasticsearch:6.8.0

docker run -d -it -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" --name es-6.8.0 docker.elastic.co/elasticsearch/elasticsearch:6.8.0

==============================================================================================================================================
参考: https://es.xiaoleilu.com/
==============================================================================================================================================

1.2 数据类型
每一个字段都会指定一个数据类型，数据类型通常如下：
简单类型，例如text、keyword、date、long、double、boolean、ip
复合类型，诸如object(json)、netsed.
特殊类型，诸如geo_point、geo_shape(地图相关类型)、completion。

（1）字符型：
		①Text：被用来索引长文本，在建立索引前会将这项文本进行分词，转化为词的组合，建立索引。允许ES来检索这些词语。Text类型不能用来排序和聚合。
		②Keyword：不需要进行分词，可以被用来检索过滤、排序和聚合。Keyword类型字段只能用本身来进行检索
（2）数字类型：byte,short,integer,Long,double,float
（3）日期类型：date
（4）二进制类型：binary

1.ik_max_word
	会将文本做最细粒度的拆分，比如会将“中华人民共和国人民大会堂”拆分为“中华人民共和国、中华人民、中华、华人、人民共和国、人民、共和国、大会堂、大会、会堂等词语。
2.ik_smart
	会做最粗粒度的拆分，比如会将“中华人民共和国人民大会堂”拆分为中华人民共和国、人民大会堂。
	

两种分词器使用的最佳实践是：索引时用ik_max_word，在搜索时用ik_smart。
即：索引时最大化的将文章内容分词，搜索时更精确的搜索到想要的结果。
输入“华为手机”，此时使用ik_smart和ik_max_word都会将华为手机拆分为华为和手机两个词，那些只包括“华为”这个词的信息也被搜索出来了，可以将华为手机添加到自定义词库.


GET /_analyze
{
  "analyzer": "standard",//"analyzer": "english","analyzer": "ik_max_word","analyzer": "ik_smart"
  "text": "Text to analyze"
}


"type" : "text", #是数据类型一般文本使用text(可分词进行模糊查询)；keyword无法被分词(不需要执行分词器)，用于精确查找
"analyzer" : "ik_max_word", #指定分词器，一般使用最大分词：ik_max_word
"normalizer" : "normalizer_name", #字段标准化规则；如把所有字符转为小写；具体如下举例
"boost" : 1.5, #字段权重；用于查询时评分，关键字段的权重就会高一些，默认都是1；另外查询时可临时指定权重
"coerce" : true, #清理脏数据：1，字符串会被强制转换为整数 2，浮点数被强制转换为整数；默认为true
"copy_to" : "field_name", #自定_all字段；指定某几个字段拼接成自定义；具体如下举例
"doc_values" : true, #加快排序、聚合操作，但需要额外存储空间；默认true，对于确定不需要排序和聚合的字段可false
"dynamic" : true, #新字段动态添加 true:无限制 false:数据可写入但该字段不保留 'strict':无法写入抛异常
"enabled" : true, #是否会被索引，但都会存储;可以针对一整个_doc
"fielddata" : false, #针对text字段加快排序和聚合（doc_values对text无效）；此项官网建议不开启，非常消耗内存
"eager_global_ordinals": true, #是否开启全局预加载,加快查询；此参数只支持text和keyword，keyword默认可用，而text需要设置fielddata属性
"format" : "yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis" ,#格式化 此参数代表可接受的时间格式 3种都接受
"ignore_above" : 100, #指定字段索引和存储的长度最大值，超过最大值的会被忽略
"ignore_malformed" : false ,#插入文档时是否忽略类型 默认是false 类型不一致无法插入
"index_options" : "docs" ,
    # 4个可选参数
    # docs（索引文档号）,
    # freqs（文档号 + 词频），
    # positions（文档号 + 词频 + 位置，通常用来距离查询），
    # offsets（文档号 + 词频 + 位置 + 偏移量，通常被使用在高亮字段）
    # 分词字段默认是position，其他的默认是docs
"index" : true, #该字段是否会被索引和可查询 默认true
"fields": {"raw": {"type": "keyword"}} ,#可以对一个字段提供多种索引模式，使用text类型做全文检索，也可使用keyword类型做聚合和排序
"norms" : true, #用于标准化文档，以便查询时计算文档的相关性。建议不开启
"null_value" : "NULL", #可以让值为null的字段显式的可索引、可搜索
"position_increment_gap" : 0 ,#词组查询时可以跨词查询 既可变为分词查询 默认100
"properties" : {}, #嵌套属性，例如该字段是音乐，音乐还有歌词，类型，歌手等属性
"search_analyzer" : "ik_max_word" ,#查询分词器;一般情况和analyzer对应
"similarity" : "BM25",#用于指定文档评分模型，参数有三个：
	# BM25 ：ES和Lucene默认的评分模型
	# classic ：TF/IDF评分
	# boolean：布尔模型评分
"store" : true, #默认情况false,其实并不是真没有存储，_source字段里会保存一份原始文档。
	# 在某些情况下，store参数有意义，比如一个文档里面有title、date和超大的content字段，如果只想获取title和date
"term_vector" : "no" #默认不存储向量信息，
	# 支持参数yes（term存储），
	# with_positions（term + 位置）,
	# with_offsets（term + 偏移量），
	# with_positions_offsets(term + 位置 + 偏移量)
	# 对快速高亮fast vector highlighter能提升性能，但开启又会加大索引体积，不适合大数据量用


PUT bk
{
  "mappings": {
    "doc": {
      "properties": {
        "name": {
          "type": "keyword"
        },
        "sex": {
          "type": "keyword"
        },
        "age": {
          "type": "long"
        },
        "book": {
          "type": "text",
          "analyzer": "ik_max_word"
        },
        "remark": {
          "type": "text",
          "analyzer": "ik_max_word"
        }
      }
    }
  }
}


==============================================================================================================================================
如果我们的数据没有自然ID，我们可以让Elasticsearch自动为我们生成。请求结构发生了变化：PUT方法——“在这个URL中存储文档”变成了POST方法——"在这个类型下存储文档"